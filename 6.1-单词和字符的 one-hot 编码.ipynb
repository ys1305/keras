{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6.1-单词和字符的 one-hot 编码.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"DxgXrcXdO2bz","colab_type":"code","outputId":"ee3146e1-9080-4131-b2a3-1c5838ea91da","executionInfo":{"status":"ok","timestamp":1554788207975,"user_tz":-480,"elapsed":2064,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["import keras\n","keras.__version__"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'2.2.4'"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"4pL1NE5KO_sJ","colab_type":"code","outputId":"de3b6f31-c6de-4762-e34a-268231ed3fec","executionInfo":{"status":"ok","timestamp":1554788260503,"user_tz":-480,"elapsed":43759,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"cell_type":"code","source":["from keras.applications.vgg16 import VGG16\n","\n","\n","# Note that we are including the densely-connected classifier on top;\n","# all previous times, we were discarding it.\n","model = VGG16(weights='imagenet')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467904/553467096 [==============================] - 37s 0us/step\n"],"name":"stdout"}]},{"metadata":{"id":"yzCIQo8_smRI","colab_type":"code","outputId":"7e47df6d-086a-4bd5-c185-cef375cb8ba9","executionInfo":{"status":"ok","timestamp":1545109415918,"user_tz":-480,"elapsed":5826,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":["!wget https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2018-12-18 05:05:30--  https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.108.37\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.108.37|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 35363 (35K) [application/octet-stream]\n","Saving to: ‘imagenet_class_index.json’\n","\n","\r          imagenet_   0%[                    ]       0  --.-KB/s               \rimagenet_class_inde 100%[===================>]  34.53K  --.-KB/s    in 0.03s   \n","\n","2018-12-18 05:05:30 (1.11 MB/s) - ‘imagenet_class_index.json’ saved [35363/35363]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"JAOe9VWYO2b-","colab_type":"text"},"cell_type":"markdown","source":["# One-hot encoding of words or characters\n","\n","This notebook contains the first code sample found in Chapter 6, Section 1 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n","\n","----\n","one-hot 编码是将标记转换为向量的最常用、最基本的方法。在第 3 章的 IMDB 和路透社两 个例子中，你已经用过这种方法（都是处理单词）。它将每个单词与一个唯一的整数索引相关联， 然后将这个整数索引 i 转换为长度为 N 的二进制向量（N 是词表大小），这个向量只有第 i 个元 素是 1，其余元素都为 0。\n","\n","当然，也可以进行字符级的 one-hot 编码。为了让你完全理解什么是 one-hot 编码以及如何 实现 one-hot 编码，代码清单 6-1 和代码清单 6-2 给出了两个简单示例，一个是单词级的 one-hot 编码，另一个是字符级的 one-hot 编码。\n","\n","Word level one-hot encoding (toy example):\n","\n","单词级的 one-hot 编码（简单示例）："]},{"metadata":{"id":"CPZIMj5OO2cA","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","# 初始数据：每个样本是列表的一个元素（本例中的样本是一个句子，但也可以是一整篇文档）\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","\n","# 构建数据中所有标记的索引\n","token_index = {}\n","for sample in samples:\n","    # 利用 split 方法对样本进行分词。在实际应用中，还需要从样本中去掉标点和特殊字符\n","    for word in sample.split():\n","        if word not in token_index:\n","            #为每个唯一单词指定一个唯一索引。\n","            token_index[word] = len(token_index) + 1\n","           #注意，没有为索引编号 0 指定单词"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3K24krmVmuKG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":190},"outputId":"63321fdd-3768-45b4-a0ea-3e3b8c19fd8d","executionInfo":{"status":"ok","timestamp":1554788321653,"user_tz":-480,"elapsed":1654,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}}},"cell_type":"code","source":["token_index"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'The': 1,\n"," 'ate': 8,\n"," 'cat': 2,\n"," 'dog': 7,\n"," 'homework.': 10,\n"," 'mat.': 6,\n"," 'my': 9,\n"," 'on': 4,\n"," 'sat': 3,\n"," 'the': 5}"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"5pPu2uxCmsTe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"f028f9ce-86ce-4d9b-ee55-01c633fe2ab5","executionInfo":{"status":"ok","timestamp":1554788446822,"user_tz":-480,"elapsed":1640,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}}},"cell_type":"code","source":["\n","# 对样本进行分词。只考虑每个 样本前 max_length 个单词\n","max_length = 10\n","\n","# This is where we store our results:（将结果保存在 results 中）\n","results = np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n","results.shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 10, 11)"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"nBLiB6vqnMSS","colab_type":"code","colab":{}},"cell_type":"code","source":["for i, sample in enumerate(samples):\n","    for j, word in list(enumerate(sample.split()))[:max_length]:\n","        index = token_index.get(word)\n","#         get() 函数返回指定键的值，如果值不在字典中返回默认值\n","        results[i, j, index] = 1."],"execution_count":0,"outputs":[]},{"metadata":{"id":"H1xa-x7nuNPU","colab_type":"code","outputId":"2f36ffbc-0aa1-41f0-bdb8-460dba57030c","executionInfo":{"status":"ok","timestamp":1554788532996,"user_tz":-480,"elapsed":1598,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}},"colab":{"base_uri":"https://localhost:8080/","height":380}},"cell_type":"code","source":["print(results)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","\n"," [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"],"name":"stdout"}]},{"metadata":{"id":"a6pC9JwvO2cD","colab_type":"text"},"cell_type":"markdown","source":["## 字符级的 one-hot 编码（简单示例）"]},{"metadata":{"id":"4qrmVebRO2cE","colab_type":"code","colab":{}},"cell_type":"code","source":["import string\n","\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","characters = string.printable  # All printable ASCII characters.（所有可打印的 ASCII 字符）\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q1-JkM5Antq6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"cf6c7f39-2cba-4372-eaa1-c05a0953c5c8","executionInfo":{"status":"ok","timestamp":1554788593920,"user_tz":-480,"elapsed":1597,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}}},"cell_type":"code","source":["characters"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"2DvyoUyvn1jv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"7ece89fd-8a27-4854-ebaf-5abb5451d4fd","executionInfo":{"status":"ok","timestamp":1554788616090,"user_tz":-480,"elapsed":1624,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}}},"cell_type":"code","source":["len(characters)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"s1pcogv8nr64","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1745},"outputId":"cb8903a0-febd-499b-eef0-065d805fcafd","executionInfo":{"status":"ok","timestamp":1554788659567,"user_tz":-480,"elapsed":1228,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}}},"cell_type":"code","source":["token_index = dict(zip(characters, range(1, len(characters) + 1)))\n","token_index"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'\\t': 96,\n"," '\\n': 97,\n"," '\\x0b': 99,\n"," '\\x0c': 100,\n"," '\\r': 98,\n"," ' ': 95,\n"," '!': 63,\n"," '\"': 64,\n"," '#': 65,\n"," '$': 66,\n"," '%': 67,\n"," '&': 68,\n"," \"'\": 69,\n"," '(': 70,\n"," ')': 71,\n"," '*': 72,\n"," '+': 73,\n"," ',': 74,\n"," '-': 75,\n"," '.': 76,\n"," '/': 77,\n"," '0': 1,\n"," '1': 2,\n"," '2': 3,\n"," '3': 4,\n"," '4': 5,\n"," '5': 6,\n"," '6': 7,\n"," '7': 8,\n"," '8': 9,\n"," '9': 10,\n"," ':': 78,\n"," ';': 79,\n"," '<': 80,\n"," '=': 81,\n"," '>': 82,\n"," '?': 83,\n"," '@': 84,\n"," 'A': 37,\n"," 'B': 38,\n"," 'C': 39,\n"," 'D': 40,\n"," 'E': 41,\n"," 'F': 42,\n"," 'G': 43,\n"," 'H': 44,\n"," 'I': 45,\n"," 'J': 46,\n"," 'K': 47,\n"," 'L': 48,\n"," 'M': 49,\n"," 'N': 50,\n"," 'O': 51,\n"," 'P': 52,\n"," 'Q': 53,\n"," 'R': 54,\n"," 'S': 55,\n"," 'T': 56,\n"," 'U': 57,\n"," 'V': 58,\n"," 'W': 59,\n"," 'X': 60,\n"," 'Y': 61,\n"," 'Z': 62,\n"," '[': 85,\n"," '\\\\': 86,\n"," ']': 87,\n"," '^': 88,\n"," '_': 89,\n"," '`': 90,\n"," 'a': 11,\n"," 'b': 12,\n"," 'c': 13,\n"," 'd': 14,\n"," 'e': 15,\n"," 'f': 16,\n"," 'g': 17,\n"," 'h': 18,\n"," 'i': 19,\n"," 'j': 20,\n"," 'k': 21,\n"," 'l': 22,\n"," 'm': 23,\n"," 'n': 24,\n"," 'o': 25,\n"," 'p': 26,\n"," 'q': 27,\n"," 'r': 28,\n"," 's': 29,\n"," 't': 30,\n"," 'u': 31,\n"," 'v': 32,\n"," 'w': 33,\n"," 'x': 34,\n"," 'y': 35,\n"," 'z': 36,\n"," '{': 91,\n"," '|': 92,\n"," '}': 93,\n"," '~': 94}"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"9VZgYWt8n9Wn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"cb79ef41-3e14-42df-e2c5-1f23c11c4c0c","executionInfo":{"status":"ok","timestamp":1554788690865,"user_tz":-480,"elapsed":1273,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}}},"cell_type":"code","source":["max_length = 50\n","results = np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n","results.shape"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 50, 101)"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"id":"J8c2djnPoISe","colab_type":"code","colab":{}},"cell_type":"code","source":["for i, sample in enumerate(samples):\n","    for j, character in enumerate(sample[:max_length]):\n","        index = token_index.get(character)\n","        results[i, j, index] = 1."],"execution_count":0,"outputs":[]},{"metadata":{"id":"3zmfYEQVujsn","colab_type":"code","outputId":"b6a2c429-e3d8-40b3-8e7d-2896d35484e0","executionInfo":{"status":"ok","timestamp":1545109929190,"user_tz":-480,"elapsed":813,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"cell_type":"code","source":["print(results)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]]]\n"],"name":"stdout"}]},{"metadata":{"id":"-5Go9PTsO2cG","colab_type":"text"},"cell_type":"markdown","source":["注意，Keras 的内置函数可以对原始文本数据进行单词级或字符级的 one-hot 编码。你应该使用这些函数，因为它们实现了许多重要的特性，比如从字符串中去除特殊字符、只考虑数据集中前 N 个最常见的单词（这是一种常用的限制，以避免处理非常大的输入向量空间）。"]},{"metadata":{"id":"1M3nn0XtO2cH","colab_type":"text"},"cell_type":"markdown","source":["## 用 Keras 实现单词级的 one-hot 编码："]},{"metadata":{"id":"mc9J4cQZO2cI","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","\n","\n","# 创建一个分词器（tokenizer），设置为只考虑前 1000 个最常见的单词\n","tokenizer = Tokenizer(num_words=1000)\n","# 将字符串转换为整数索引组成的列表\n","tokenizer.fit_on_texts(samples)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WauAuHAGzf8S","colab_type":"code","colab":{}},"cell_type":"code","source":["# 将字符串转换为整数索引组成的列表\n","sequences = tokenizer.texts_to_sequences(samples)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"r3G9_Q6hoz11","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"dd6b4f4f-b22a-4e7a-ab93-492e4bb5d052","executionInfo":{"status":"ok","timestamp":1554788890754,"user_tz":-480,"elapsed":1158,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}}},"cell_type":"code","source":["len(sequences[0])"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{"tags":[]},"execution_count":21}]},{"metadata":{"id":"J9F6TfKJzgKw","colab_type":"code","outputId":"9949e698-c541-4d1c-d5cd-23690bb2a560","executionInfo":{"status":"ok","timestamp":1554788808712,"user_tz":-480,"elapsed":1447,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["print(sequences)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]\n"],"name":"stdout"}]},{"metadata":{"id":"aIN_7URNzgdL","colab_type":"code","colab":{}},"cell_type":"code","source":["# （也可以直接得到 one-hot 二进制表示。）这个分词器也支持除 one-hot 编码外的其他向量化模式\n","one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"d8wlL7Qtzpl4","colab_type":"code","outputId":"e872bd01-2cab-4392-f027-972a077946a1","executionInfo":{"status":"ok","timestamp":1554788843077,"user_tz":-480,"elapsed":1220,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["print(one_hot_results)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[[0. 1. 1. ... 0. 0. 0.]\n"," [0. 1. 0. ... 0. 0. 0.]]\n"],"name":"stdout"}]},{"metadata":{"id":"q8LltXkmzpvp","colab_type":"code","outputId":"9b0dc88b-e2ed-4422-d601-fcb9737493fd","executionInfo":{"status":"ok","timestamp":1554788847990,"user_tz":-480,"elapsed":1603,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["one_hot_results.shape"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 1000)"]},"metadata":{"tags":[]},"execution_count":19}]},{"metadata":{"id":"owbejoN-zp2Q","colab_type":"code","outputId":"8317c9ab-428c-49a4-8ad5-c0e3878cb71e","executionInfo":{"status":"ok","timestamp":1554788924165,"user_tz":-480,"elapsed":1616,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"cell_type":"code","source":["# （找回单词索引）\n","word_index = tokenizer.word_index\n","print(word_index)\n","print('Found %s unique tokens.' % len(word_index))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["{'the': 1, 'cat': 2, 'sat': 3, 'on': 4, 'mat': 5, 'dog': 6, 'ate': 7, 'my': 8, 'homework': 9}\n","Found 9 unique tokens.\n"],"name":"stdout"}]},{"metadata":{"id":"Y8zNHAoqO2cM","colab_type":"text"},"cell_type":"markdown","source":["one-hot 编码的一种变体是所谓的 one-hot 散列技巧（one-hot hashing trick），如果词表中唯 一标记的数量太大而无法直接处理，就可以使用这种技巧。这种方法没有为每个单词显式分配 一个索引并将这些索引保存在一个字典中，而是将单词散列编码为固定长度的向量，通常用一个非常简单的散列函数来实现。这种方法的主要优点在于，它避免了维护一个显式的单词索引， 从而节省内存并允许数据的在线编码（在读取完所有数据之前，你就可以立刻生成标记向量）。 这种方法有一个缺点，就是可能会出现散列冲突（hash collision），即两个不同的单词可能具有相同的散列值，随后任何机器学习模型观察这些散列值，都无法区分它们所对应的单词。\n","\n","如果散列空间的维度远大于需要散列的唯一标记的个数，散列冲突的可能性会减小。"]},{"metadata":{"id":"zBOaGlqDO2cQ","colab_type":"text"},"cell_type":"markdown","source":["## 使用散列技巧的单词级的 one-hot 编码（简单示例）："]},{"metadata":{"id":"Bfy1OMHdO2cR","colab_type":"code","colab":{}},"cell_type":"code","source":["samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","\n","# 将单词保存为长度为 1000 的向量。如果单词数量接近 1000 个（或更多），\n","# 那么会遇到很多散列冲突，这会降低这种编码方法的准确性\n","dimensionality = 1000\n","max_length = 10\n","\n","results = np.zeros((len(samples), max_length, dimensionality))\n","for i, sample in enumerate(samples):\n","    for j, word in list(enumerate(sample.split()))[:max_length]:\n","        #将单词散列为 0~1000 范围内的一个随机整数索引\n","        index = abs(hash(word)) % dimensionality\n","        results[i, j, index] = 1."],"execution_count":0,"outputs":[]},{"metadata":{"id":"Uqt-o3ZyvY1o","colab_type":"code","outputId":"7ba0cd46-9e8a-4b38-984e-bc862220cecc","executionInfo":{"status":"ok","timestamp":1554789036717,"user_tz":-480,"elapsed":1122,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}},"colab":{"base_uri":"https://localhost:8080/","height":276}},"cell_type":"code","source":["print(results)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[[[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]]]\n"],"name":"stdout"}]},{"metadata":{"id":"3_Fyy0dwvjbx","colab_type":"code","outputId":"d332f5ba-32a2-45e9-87f9-5be2bfb0e211","executionInfo":{"status":"ok","timestamp":1554789040333,"user_tz":-480,"elapsed":1488,"user":{"displayName":"Sen Yang","photoUrl":"","userId":"00832503676208839570"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["results.shape"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 10, 1000)"]},"metadata":{"tags":[]},"execution_count":25}]},{"metadata":{"id":"-giopgYsvnIx","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}